[
  {
    "objectID": "posts/Modelling 1/Modelling 1.html",
    "href": "posts/Modelling 1/Modelling 1.html",
    "title": "Part 2",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(performance)\nlibrary(ordinal)\nlibrary(car)\nlibrary(ggeffects)\nlibrary(gofcat)\nlibrary(brms)\nlibrary(emmeans)\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(MASS) \nlibrary(reshape2) \nlibrary(reshape) \nlibrary(logistf)\nlibrary(corrplot)\n\n##Modelling 1\nThe next phase in the analysis is to begin constructing some ordinal regression models describing the relationship between demographic data and thought types.\nI’m starting by filtering through the demographic variables for each thought type, and seeing which ones, if any, have effects on thought types in an ordinal regression model.\n\ninput &lt;- \"https://raw.githubusercontent.com/hw3446/Final_Project_PUC/main/data/data.csv\"\n\ndata &lt;- read_csv(input)\n\n\n# List to store results\nmodels &lt;- list()\nstepwise_models &lt;- list()\n\n# List of outcome variables\noutcome_vars &lt;- c(\"Fictional_story\", \"Abstract_shapes\", \"Sensory_sensations\", \n                  \"Life_experiences\", \"Media\", \"Music\", \"Future_plans\", \n                  \"Building\", \"Everyday\")\n\n# Converting outcome variables to factors with consistent levels for each thought type\ndata[outcome_vars] &lt;- lapply(data[outcome_vars], factor, \n                             levels = c(\"Not at all\", \"A small amount of the time\", \n                                        \"A moderate amount of the time\", \"Most of the time\", \n                                        \"All of the time\"))\n\n\n#Making sure demographic variables are classed in the right way.\ndata$Age &lt;- as.numeric(data$Age)\ndata$Practice &lt;- as.numeric(as.character(data$Practice))\ndata$Gender &lt;- factor(data$Gender,  levels = c('Male', 'Female', 'Other'))\ndata$Music_listening &lt;- factor(data$Music_listening, levels = c('Very rarely', 'Somewhat rarely', 'Moderately frequently', 'Frequently', 'Very frequently'))\ndata$Floor &lt;- factor(data$Floor, levels = c('Downstairs', 'Upstairs'))\n\n\n# Loop through selected outcomes\nfor (outcome in outcome_vars) {\n  formula &lt;- as.formula(paste(outcome, \"~ Age + Gender + Music_listening + Practice + Floor\"))\n  \n  # Drop rows with NA values in the outcome or predictors\n  vars_to_check &lt;- c(outcome, \"Age\", \"Gender\", \"Music_listening\", \"Practice\", \"Floor\")\n  data_subset &lt;- data[complete.cases(data[vars_to_check]), ]\n\n  # Debugging message\n  cat(\"\\nProcessing:\", outcome, \n      \" | Rows before:\", nrow(data), \n      \" | Rows after NA removal:\", nrow(data_subset), \"\\n\")\n\n  tryCatch({\n    # Fit proportional odds model\n    model &lt;- polr(formula, data = data_subset, Hess = TRUE, method = \"probit\", \n                  control = list(maxit = 1000), na.action = na.exclude)\n    \n    # Store model\n    models[[outcome]] &lt;- model\n    \n    # Print summary\n    cat(\"\\nSummary for\", outcome, \":\\n\")\n    print(summary(model))\n    \n    # Perform stepwise regression\n    step_model &lt;- step(model, direction = \"backward\", trace = FALSE)\n    stepwise_models[[outcome]] &lt;- step_model\n    \n    # Print stepwise summary\n    cat(\"\\nStepwise Model Summary for\", outcome, \":\\n\")\n    print(summary(step_model))\n    \n  }, error = function(e) {\n    cat(\"\\nSkipping\", outcome, \"due to error:\", conditionMessage(e), \"\\n\")\n  })\n}\n\n\nProcessing: Fictional_story  | Rows before: 84  | Rows after NA removal: 61 \n\n\n\nSummary for Fictional_story :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                         Value Std. Error   t value\nAge                                  -0.001074   0.008367 -0.128353\nGenderFemale                         -0.146478   0.295069 -0.496420\nMusic_listeningSomewhat rarely        0.196832   1.285168  0.153156\nMusic_listeningModerately frequently -0.149644   1.168670 -0.128047\nMusic_listeningFrequently             0.130946   1.131141  0.115765\nMusic_listeningVery frequently       -0.009055   1.158496 -0.007816\nPractice                             -0.021158   0.009452 -2.238525\nFloorUpstairs                         0.078698   0.404125  0.194736\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -0.8221  1.1152   \nA small amount of the time|A moderate amount of the time  0.0458  1.1123   \nA moderate amount of the time|Most of the time            0.7709  1.1248   \nMost of the time|All of the time                          1.3847  1.1439   \n                                                         t value\nNot at all|A small amount of the time                    -0.7371\nA small amount of the time|A moderate amount of the time  0.0412\nA moderate amount of the time|Most of the time            0.6854\nMost of the time|All of the time                          1.2106\n\nResidual Deviance: 168.3786 \nAIC: 192.3786 \n\n\n\nStepwise Model Summary for Fictional_story :\nCall:\npolr(formula = Fictional_story ~ Practice, data = data_subset, \n    control = list(maxit = 1000), na.action = na.exclude, Hess = TRUE, \n    method = \"probit\")\n\nCoefficients:\n            Value Std. Error t value\nPractice -0.02015   0.008693  -2.318\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -0.7494  0.2131   \nA small amount of the time|A moderate amount of the time  0.1085  0.1971   \nA moderate amount of the time|Most of the time            0.8360  0.2193   \nMost of the time|All of the time                          1.4498  0.2874   \n                                                         t value\nNot at all|A small amount of the time                    -3.5160\nA small amount of the time|A moderate amount of the time  0.5503\nA moderate amount of the time|Most of the time            3.8118\nMost of the time|All of the time                          5.0444\n\nResidual Deviance: 169.4059 \nAIC: 179.4059 \n\nProcessing: Abstract_shapes  | Rows before: 84  | Rows after NA removal: 61 \n\n\n\nSummary for Abstract_shapes :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                         Value Std. Error t value\nAge                                   0.001271   0.009014  0.1410\nGenderFemale                          0.093205   0.319961  0.2913\nMusic_listeningSomewhat rarely       -1.477958   1.359519 -1.0871\nMusic_listeningModerately frequently -2.124072   1.229084 -1.7282\nMusic_listeningFrequently            -0.995012   1.163714 -0.8550\nMusic_listeningVery frequently       -0.690983   1.192354 -0.5795\nPractice                             -0.016750   0.010302 -1.6259\nFloorUpstairs                        -0.475930   0.435169 -1.0937\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -1.4611  1.1532   \nA small amount of the time|A moderate amount of the time -0.5559  1.1405   \nA moderate amount of the time|Most of the time            0.4785  1.1387   \nMost of the time|All of the time                          0.7653  1.1656   \n                                                         t value\nNot at all|A small amount of the time                    -1.2669\nA small amount of the time|A moderate amount of the time -0.4874\nA moderate amount of the time|Most of the time            0.4202\nMost of the time|All of the time                          0.6565\n\nResidual Deviance: 119.5797 \nAIC: 143.5797 \n\n\n\nStepwise Model Summary for Abstract_shapes :\nCall:\npolr(formula = Abstract_shapes ~ Music_listening + Practice, \n    data = data_subset, control = list(maxit = 1000), na.action = na.exclude, \n    Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                        Value Std. Error t value\nMusic_listeningSomewhat rarely       -1.98179    1.23690  -1.602\nMusic_listeningModerately frequently -2.39434    1.13347  -2.112\nMusic_listeningFrequently            -1.31041    1.10308  -1.188\nMusic_listeningVery frequently       -1.12628    1.07945  -1.043\nPractice                             -0.01793    0.01011  -1.773\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -1.5863  1.0793   \nA small amount of the time|A moderate amount of the time -0.6972  1.0639   \nA moderate amount of the time|Most of the time            0.3386  1.0631   \nMost of the time|All of the time                          0.6327  1.0972   \n                                                         t value\nNot at all|A small amount of the time                    -1.4698\nA small amount of the time|A moderate amount of the time -0.6553\nA moderate amount of the time|Most of the time            0.3185\nMost of the time|All of the time                          0.5766\n\nResidual Deviance: 121.0018 \nAIC: 139.0018 \n\nProcessing: Sensory_sensations  | Rows before: 84  | Rows after NA removal: 61 \n\n\n\nSummary for Sensory_sensations :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                        Value Std. Error t value\nAge                                   0.02476    0.01054  2.3489\nGenderFemale                          0.27112    0.36272  0.7475\nMusic_listeningSomewhat rarely        3.59638    0.58580  6.1392\nMusic_listeningModerately frequently  3.00268    0.41736  7.1944\nMusic_listeningFrequently             4.32913    0.32113 13.4807\nMusic_listeningVery frequently        4.01011    0.31958 12.5482\nPractice                             -0.02515    0.01132 -2.2227\nFloorUpstairs                        -0.21556    0.43701 -0.4933\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                     5.2045  0.5928   \nA small amount of the time|A moderate amount of the time  6.0390  0.6292   \nA moderate amount of the time|Most of the time            6.6223  0.6993   \nMost of the time|All of the time                         11.3879  0.6993   \n                                                         t value\nNot at all|A small amount of the time                     8.7791\nA small amount of the time|A moderate amount of the time  9.5985\nA moderate amount of the time|Most of the time            9.4701\nMost of the time|All of the time                         16.2851\n\nResidual Deviance: 95.99886 \nAIC: 119.9989 \n\n\n\nStepwise Model Summary for Sensory_sensations :\nCall:\npolr(formula = Sensory_sensations ~ Age + Practice, data = data_subset, \n    control = list(maxit = 1000), na.action = na.exclude, Hess = TRUE, \n    method = \"probit\")\n\nCoefficients:\n            Value Std. Error t value\nAge       0.01568   0.008905   1.761\nPractice -0.01784   0.010245  -1.741\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                     1.0503  0.5039   \nA small amount of the time|A moderate amount of the time  1.8248  0.5331   \nA moderate amount of the time|Most of the time            2.3367  0.5813   \nMost of the time|All of the time                          5.4469 18.4486   \n                                                         t value\nNot at all|A small amount of the time                     2.0844\nA small amount of the time|A moderate amount of the time  3.4230\nA moderate amount of the time|Most of the time            4.0200\nMost of the time|All of the time                          0.2952\n\nResidual Deviance: 103.7518 \nAIC: 115.7518 \n\nProcessing: Life_experiences  | Rows before: 84  | Rows after NA removal: 61 \n\n\n\nSummary for Life_experiences :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                        Value Std. Error t value\nAge                                  -0.02225   0.008496 -2.6187\nGenderFemale                          0.20244   0.287339  0.7045\nMusic_listeningSomewhat rarely       -0.42582   1.291673 -0.3297\nMusic_listeningModerately frequently  0.24876   1.183557  0.2102\nMusic_listeningFrequently             0.11775   1.150719  0.1023\nMusic_listeningVery frequently        0.18804   1.170665  0.1606\nPractice                             -0.01583   0.009241 -1.7133\nFloorUpstairs                        -0.05942   0.395468 -0.1503\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -2.0873  1.1514   \nA small amount of the time|A moderate amount of the time -1.1389  1.1338   \nA moderate amount of the time|Most of the time           -0.0187  1.1278   \nMost of the time|All of the time                          0.9150  1.1592   \n                                                         t value\nNot at all|A small amount of the time                    -1.8128\nA small amount of the time|A moderate amount of the time -1.0045\nA moderate amount of the time|Most of the time           -0.0165\nMost of the time|All of the time                          0.7893\n\nResidual Deviance: 160.8484 \nAIC: 184.8484 \n\n\n\nStepwise Model Summary for Life_experiences :\nCall:\npolr(formula = Life_experiences ~ Age + Practice, data = data_subset, \n    control = list(maxit = 1000), na.action = na.exclude, Hess = TRUE, \n    method = \"probit\")\n\nCoefficients:\n            Value Std. Error t value\nAge      -0.02116   0.007521  -2.813\nPractice -0.01476   0.008576  -1.721\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -2.1970  0.4624   \nA small amount of the time|A moderate amount of the time -1.2615  0.4227   \nA moderate amount of the time|Most of the time           -0.1595  0.4067   \nMost of the time|All of the time                          0.7564  0.4659   \n                                                         t value\nNot at all|A small amount of the time                    -4.7513\nA small amount of the time|A moderate amount of the time -2.9842\nA moderate amount of the time|Most of the time           -0.3921\nMost of the time|All of the time                          1.6235\n\nResidual Deviance: 162.6645 \nAIC: 174.6645 \n\nProcessing: Media  | Rows before: 84  | Rows after NA removal: 61 \n\n\n\nSummary for Media :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                         Value Std. Error t value\nAge                                   0.004096   0.009031  0.4535\nGenderFemale                         -0.237291   0.322584 -0.7356\nMusic_listeningSomewhat rarely        5.905293   0.490346 12.0431\nMusic_listeningModerately frequently  4.151073   0.353335 11.7483\nMusic_listeningFrequently             5.017131   0.289628 17.3227\nMusic_listeningVery frequently        5.130711   0.289774 17.7059\nPractice                             -0.022223   0.010437 -2.1293\nFloorUpstairs                        -0.347515   0.439608 -0.7905\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                     4.4974  0.5439   \nA small amount of the time|A moderate amount of the time  5.4229  0.5417   \nA moderate amount of the time|Most of the time            6.2040  0.5840   \nMost of the time|All of the time                         10.6364  0.5840   \n                                                         t value\nNot at all|A small amount of the time                     8.2683\nA small amount of the time|A moderate amount of the time 10.0116\nA moderate amount of the time|Most of the time           10.6234\nMost of the time|All of the time                         18.2131\n\nResidual Deviance: 120.8456 \nAIC: 144.8456 \n\n\n\nStepwise Model Summary for Media :\nCall:\npolr(formula = Media ~ Music_listening + Practice, data = data_subset, \n    control = list(maxit = 1000), na.action = na.exclude, Hess = TRUE, \n    method = \"probit\")\n\nCoefficients:\n                                       Value Std. Error t value\nMusic_listeningSomewhat rarely        5.2295     0.4401  11.884\nMusic_listeningModerately frequently  3.7457     0.2942  12.732\nMusic_listeningFrequently             4.5367     0.2845  15.947\nMusic_listeningVery frequently        4.5158     0.2325  19.419\nPractice                             -0.0238     0.0102  -2.333\n\nIntercepts:\n                                                         Value    Std. Error\nNot at all|A small amount of the time                      4.1209   0.1882  \nA small amount of the time|A moderate amount of the time   5.0257   0.2075  \nA moderate amount of the time|Most of the time             5.7994   0.2751  \nMost of the time|All of the time                           9.7697 109.9753  \n                                                         t value \nNot at all|A small amount of the time                     21.8965\nA small amount of the time|A moderate amount of the time  24.2257\nA moderate amount of the time|Most of the time            21.0784\nMost of the time|All of the time                           0.0888\n\nResidual Deviance: 122.9507 \nAIC: 140.9507 \n\nProcessing: Music  | Rows before: 84  | Rows after NA removal: 60 \n\n\n\nSummary for Music :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                         Value Std. Error t value\nAge                                  -0.004468   0.008593 -0.5199\nGenderFemale                          0.194068   0.297491  0.6523\nMusic_listeningSomewhat rarely        0.449359   1.312317  0.3424\nMusic_listeningModerately frequently  1.265349   1.189638  1.0636\nMusic_listeningFrequently             1.285028   1.156238  1.1114\nMusic_listeningVery frequently        1.542188   1.182027  1.3047\nPractice                              0.024122   0.009543  2.5278\nFloorUpstairs                        -0.436482   0.419113 -1.0414\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -4.1708 12.2018   \nA small amount of the time|A moderate amount of the time -0.1838  1.1183   \nA moderate amount of the time|Most of the time            0.8053  1.1265   \nMost of the time|All of the time                          2.4567  1.1531   \n                                                         t value\nNot at all|A small amount of the time                    -0.3418\nA small amount of the time|A moderate amount of the time -0.1644\nA moderate amount of the time|Most of the time            0.7148\nMost of the time|All of the time                          2.1304\n\nResidual Deviance: 131.5353 \nAIC: 155.5353 \n\n\n\nStepwise Model Summary for Music :\nCall:\npolr(formula = Music ~ Practice, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n           Value Std. Error t value\nPractice 0.02512   0.008792   2.857\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -4.4808 24.9395   \nA small amount of the time|A moderate amount of the time -0.9346  0.2347   \nA moderate amount of the time|Most of the time           -0.0256  0.1991   \nMost of the time|All of the time                          1.5688  0.2741   \n                                                         t value\nNot at all|A small amount of the time                    -0.1797\nA small amount of the time|A moderate amount of the time -3.9825\nA moderate amount of the time|Most of the time           -0.1287\nMost of the time|All of the time                          5.7229\n\nResidual Deviance: 136.9328 \nAIC: 146.9328 \n\nProcessing: Future_plans  | Rows before: 84  | Rows after NA removal: 58 \n\n\n\nSummary for Future_plans :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                        Value Std. Error t value\nAge                                  -0.02398   0.009323 -2.5719\nGenderFemale                         -0.38286   0.307048 -1.2469\nMusic_listeningSomewhat rarely        0.76891   1.295553  0.5935\nMusic_listeningModerately frequently -0.33201   1.171041 -0.2835\nMusic_listeningFrequently            -0.47619   1.134170 -0.4199\nMusic_listeningVery frequently       -0.18523   1.163575 -0.1592\nPractice                             -0.02811   0.011861 -2.3700\nFloorUpstairs                         0.04684   0.421922  0.1110\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -2.5089  1.1496   \nA small amount of the time|A moderate amount of the time -1.6860  1.1278   \nA moderate amount of the time|Most of the time           -0.9847  1.1210   \nMost of the time|All of the time                          0.3438  1.1679   \n                                                         t value\nNot at all|A small amount of the time                    -2.1825\nA small amount of the time|A moderate amount of the time -1.4950\nA moderate amount of the time|Most of the time           -0.8784\nMost of the time|All of the time                          0.2944\n\nResidual Deviance: 149.1068 \nAIC: 173.1068 \n\n\n\nStepwise Model Summary for Future_plans :\nCall:\npolr(formula = Future_plans ~ Age + Practice, data = data_subset, \n    control = list(maxit = 1000), na.action = na.exclude, Hess = TRUE, \n    method = \"probit\")\n\nCoefficients:\n            Value Std. Error t value\nAge      -0.02124   0.008144  -2.609\nPractice -0.03079   0.011149  -2.761\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -2.0072  0.4838   \nA small amount of the time|A moderate amount of the time -1.2319  0.4638   \nA moderate amount of the time|Most of the time           -0.5677  0.4514   \nMost of the time|All of the time                          0.6554  0.4905   \n                                                         t value\nNot at all|A small amount of the time                    -4.1492\nA small amount of the time|A moderate amount of the time -2.6559\nA moderate amount of the time|Most of the time           -1.2575\nMost of the time|All of the time                          1.3361\n\nResidual Deviance: 154.6512 \nAIC: 166.6512 \n\nProcessing: Building  | Rows before: 84  | Rows after NA removal: 59 \n\n\n\nSkipping Building due to error: initial value in 'vmmin' is not finite \n\nProcessing: Everyday  | Rows before: 84  | Rows after NA removal: 59 \n\n\n\nSummary for Everyday :\nCall:\npolr(formula = formula, data = data_subset, control = list(maxit = 1000), \n    na.action = na.exclude, Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                                        Value Std. Error  t value\nAge                                  -0.01726   0.008709 -1.98168\nGenderFemale                         -0.05770   0.294993 -0.19559\nMusic_listeningSomewhat rarely       -0.24774   1.305694 -0.18974\nMusic_listeningModerately frequently  0.69493   1.194269  0.58189\nMusic_listeningFrequently             0.70559   1.163648  0.60636\nMusic_listeningVery frequently        0.95569   1.188091  0.80439\nPractice                             -0.02188   0.009692 -2.25721\nFloorUpstairs                        -0.03675   0.404641 -0.09083\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -1.3507  1.1475   \nA small amount of the time|A moderate amount of the time -0.1688  1.1396   \nA moderate amount of the time|Most of the time            0.7742  1.1506   \nMost of the time|All of the time                          1.9241  1.2117   \n                                                         t value\nNot at all|A small amount of the time                    -1.1770\nA small amount of the time|A moderate amount of the time -0.1481\nA moderate amount of the time|Most of the time            0.6729\nMost of the time|All of the time                          1.5879\n\nResidual Deviance: 149.0369 \nAIC: 173.0369 \n\n\n\nStepwise Model Summary for Everyday :\nCall:\npolr(formula = Everyday ~ Age + Practice, data = data_subset, \n    control = list(maxit = 1000), na.action = na.exclude, Hess = TRUE, \n    method = \"probit\")\n\nCoefficients:\n            Value Std. Error t value\nAge      -0.01528   0.007472  -2.045\nPractice -0.01684   0.008812  -1.911\n\nIntercepts:\n                                                         Value   Std. Error\nNot at all|A small amount of the time                    -1.8182  0.4469   \nA small amount of the time|A moderate amount of the time -0.6863  0.4165   \nA moderate amount of the time|Most of the time            0.2035  0.4130   \nMost of the time|All of the time                          1.3080  0.5218   \n                                                         t value\nNot at all|A small amount of the time                    -4.0686\nA small amount of the time|A moderate amount of the time -1.6478\nA moderate amount of the time|Most of the time            0.4928\nMost of the time|All of the time                          2.5066\n\nResidual Deviance: 153.4401 \nAIC: 165.4401 \n\n\nEmmeans plots can be used to visualise the ordinal regression models, as shown below here for the relationship between Age and each thought type.\n\n# Only some of the outcome variables can be successfully plotted\nlibrary(gridExtra)\n\nplot_list &lt;- list()\nfor (outcome in outcome_vars) {\nmodel &lt;- polr(as.formula(paste(outcome, \"~ Age\")), data = data, Hess = TRUE)\n\npredicted_probs &lt;- ggemmeans(model, terms = c(\"Age\"))\n  \nplot &lt;- ggplot(predicted_probs, aes(x = x, y = predicted, fill = response.level)) +\n    geom_area() + \n    labs(x = \"\\nAge\", \n         y = \"Predicted Probability\\n\", \n         title = paste(outcome, \"by Age\")) +\n    scale_fill_manual(name = NULL,\n                      values = setNames(c(\"#deebf7\", \"#9ecae1\", \"#3182bd\", \"#08519c\", \"#08306b\"),\n                                        levels(data[[outcome]])),\n                      labels = c(\"Not at all\", \"A small amount of the time\", \"A moderate amount of the time\", \"Most of the time\", \"All of the time\"),\n                      breaks = c(\"Not at all\", \"A small amount of the time\", \"A moderate amount of the time\", \"Most of the time\", \"All of the time\")\n                      ) + theme_minimal()\n  \n\n  plot_list[[outcome]] &lt;- plot\n}\n\ntitle_grob &lt;- textGrob(\"Types of Thoughts by Age, First Half\", gp = gpar(fontsize = 16, fontface = \"bold\"))\n\nAge_thoughts_models &lt;- grid.arrange(\n  grobs = plot_list, \n  ncol = 3, \n  top = title_grob  \n)\n\n\n\n\n\n\n\n\nAfter narrowing down models using the step() method above, the main predictors are Music_listening and Practice for abstract shapes, Age for life experiences, Practice for music, and Age and practice for future plans. These can be plotted below.\n\nmod1 &lt;- polr(formula = Abstract_shapes ~ Practice + Music_listening, data = data, Hess = TRUE, method = \"probit\")\nmod2 &lt;- polr(formula = Life_experiences ~ Age, data = data, Hess = TRUE, method = \"probit\")\nmod3 &lt;- polr(formula = Music ~ Practice, data = data, Hess = TRUE, method = \"probit\")\nmod4 &lt;- polr(formula = Future_plans ~ Age + Practice, data = data, Hess = TRUE, method = \"probit\")\n\npred1 &lt;- ggemmeans(mod1, terms = c(\"Practice\", \"Music_listening\"))\npred2 &lt;- ggemmeans(mod2, terms = c(\"Age\"))\npred3 &lt;- ggemmeans(mod3, terms = c(\"Practice\"))\npred4 &lt;- ggemmeans(mod4, terms = c(\"Age\", \"Practice\"))\n\ncustom_colors &lt;- c(\"Not at all\" = \"#deebf7\", \n                   \"A small amount of the time\" = \"#9ecae1\", \n                   \"A moderate amount of the time\" = \"#3182bd\", \n                   \"Most of the time\" = \"#08519c\", \n                   \"All of the time\" = \"#08306b\")\n\n\n# Plot for Abstract Shapes by Music Listening & Practice\np1 &lt;- ggplot(pred1, aes(x = x, y = predicted, fill = response.level)) +\n     geom_area(alpha = 1) + \n     facet_wrap(~ group, scales = \"free_y\") +  \n     labs(x = \"Practice\", y = \"Predicted Probability\\n\", title = \"Abstract Shapes by Practice, Faceted by Classical Music Listening\") +\n     scale_fill_manual(name = NULL, values = custom_colors) +\n     theme_minimal() +\n     theme(legend.position = \"bottom\")\n\n\n# Plot Life Experiences by Age\np2 &lt;- ggplot(pred2, aes(x = x, y = predicted, fill = response.level)) +\n  geom_area() + \n  labs(x = \"\\nAge\", y = \"Predicted Probability\\n\", title = \"Life Experiences by Age\") +\n  scale_fill_manual(name = NULL, values = custom_colors) +\n  theme_minimal()\n\n\n# Plot for Music by Practice\np3 &lt;- ggplot(pred3, aes(x = x, y = predicted, fill = response.level)) +\n  geom_area() + \n  labs(x = \"\\nPractice\", y = \"Predicted Probability\\n\", title = \"Music by Practice\") +\n  scale_fill_manual(name = NULL, values = custom_colors) +\n  theme_minimal()\n\n\n#Plot for Future Plans by Age & Practice -- converting practice into a grouped variable for readability\npractice_grouped_data &lt;- practice_grouped_data &lt;- data %&gt;%\n  mutate(Practice_grouped = cut(Practice, \n                                breaks = seq(min(Practice, na.rm = TRUE), \n                                            max(Practice, na.rm = TRUE), \n                                            by = 10)))\n\nmod5 &lt;- polr(formula = Future_plans ~ Age + Practice_grouped, data = practice_grouped_data, Hess = TRUE, method = \"probit\")\n\npred5 &lt;- ggemmeans(mod5, terms = c(\"Age\", \"Practice_grouped\"))\n\np4 &lt;- ggplot(pred5, aes(x = x, y = predicted, fill = response.level)) +\n     geom_area(alpha = 1) +\n     facet_wrap(~ group, scales = \"free_y\") +  # Facet by Practice\n     labs(x = \"\\nAge\", y = \"Predicted Probability\\n\", title = \"Future Plans by Age, Faceted by Practice\") +\n     scale_fill_manual(name = NULL, values = custom_colors) +\n     theme_minimal() +\n     theme(legend.position = \"bottom\")\n\nWe can also examine the nature of the interactions between demographics variables. The vif() outputs below indicate that multicollinearity shouldn’t be a problem.\n\ndemographics &lt;- c('Age', 'Gender', 'Music_listening', 'Practice', 'Floor')\ndemographics_data &lt;- dplyr::select(data, all_of(demographics))\n\n# Convert categorical variables to numeric\ndemographics_numeric &lt;- demographics_data %&gt;%\n  mutate(\n    Gender = as.numeric(factor(Gender)),\n    Music_listening = as.numeric(factor(Music_listening, ordered = TRUE)),  \n    Floor = as.numeric(factor(Floor))\n  ) \n\n# Compute correlation matrix\ncor_matrix &lt;- cor(demographics_numeric, use = \"pairwise.complete.obs\")\n\n# Plot heatmap\ncorrplot(cor_matrix, method = \"color\", type = \"lower\", \n         tl.col = \"black\", tl.srt = 45, addCoef.col = \"white\", \n         col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(200))\n\n\n\n\n\n\n\n#Here's another way of visualising the interactions\nggplot(data, aes(x = Age, y = Practice, color = Floor)) +\n  geom_point(alpha = 0.6) +  \n  geom_smooth(method = \"lm\", se = FALSE, linetype = \"dashed\") +\n  facet_wrap(~ Floor) +\n  labs(title = \"Age vs. Practice by Floor\",\n       x = \"Age\", \n       y = \"Practice (Number of Years)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n#Checking for collinearity\nmodel1 &lt;- lm(Age ~ Practice + Gender + Music_listening + Floor, data = demographics_numeric)\nmodel2 &lt;- lm(Gender ~ Age + Practice + Music_listening + Floor, data = demographics_numeric)\nmodel3 &lt;- lm(Practice ~ Age + Gender + Music_listening + Floor, data = demographics_numeric)\nmodel4 &lt;- lm(Music_listening ~ Age + Gender + Practice + Floor, data = demographics_numeric)\nmodel5 &lt;- lm(Floor ~ Age + Gender + Practice + Music_listening, data = demographics_numeric)\nvif(model1)\n\n       Practice          Gender Music_listening           Floor \n       1.091853        1.032313        1.114286        1.112759 \n\nvif(model2)\n\n            Age        Practice Music_listening           Floor \n       1.061276        1.107218        1.114276        1.136213 \n\nvif(model3)\n\n            Age          Gender Music_listening           Floor \n       1.059136        1.044730        1.060017        1.130097 \n\nvif(model4)\n\n     Age   Gender Practice    Floor \n1.074120 1.044797 1.053371 1.119429 \n\nvif(model5)\n\n            Age          Gender        Practice Music_listening \n       1.030322        1.023328        1.078698        1.075257"
  },
  {
    "objectID": "posts/Dataset overview/Dataset_overview.html",
    "href": "posts/Dataset overview/Dataset_overview.html",
    "title": "Dataset_overview",
    "section": "",
    "text": "This dataset examines the musical imaginings that people experience in a live concert setting. The data was collected in a survey format.\nFor some background, the survey in question was distributed at a classical concert in the Princeton University Concerts series (Feb 20th, 2025). During the concert’s intermission, and at the end of the concert, audience members answered a series of questions designed to scrutinise the nature of their imaginative responses to the music performed. Distribution was via both paper surveys, and online using Qualtrics. In each part of the survey, the audience were asked about the frequency with which they experienced different types of thought, memory and imagining. They then identified the musical movements during which they imagined the most vivid fictional scenes and memories, and provided free-text responses describing these.\nYou can find a PDF of the paper survey here for reference:\nhttps://raw.githubusercontent.com/hw3446/Final_Project_PUC/59ab7bc00c7b9a0fc35517cc5b3335cf23fdc4ab/Paper_survey.pdf\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nThe data is in two halves for intermission and post-concert data. It is also divided into paper and online data. We’ll start by loading all the intermission data.\n\nlibrary(conflicted)\nconflict_prefer(\"filter\", \"dplyr\")\n\ndata_paper &lt;- read_csv(\"https://raw.githubusercontent.com/hw3446/Final_Project_PUC/main/input/PUC1.csv\")\n\ndata_qualtrics &lt;- read_csv(\"https://raw.githubusercontent.com/hw3446/Final_Project_PUC/main/input_qualtrics/PUC1.csv\")\n\nIn order to combine the two intermission datasets, we need to reshape them a little bit.\n\n##Here I'm just recoding some of the numeric values in the paper dataset to align with their likert scale values, for readability.\n\nrecode &lt;- c(\"1\" = \"Not at all\",\n                \"2\" = \"A small amount of the time\",\n                \"3\" = \"A moderate amount of the time\",\n                \"4\" = \"Most of the time\",\n                \"5\" = \"All of the time\")\n\nrecode2 &lt;- c(\"1\" = \"Not at all\",\n             \"2\" = \"Slightly\",\n             \"3\" = \"Moderately\",\n             \"4\" = \"Mostly\",\n             \"5\" = \"Entirely\")\n\nrecode3 &lt;- c(\"1\" = \"Very rarely\",\n             \"2\" = \"Somewhat rarely\",\n             \"3\" = \"Moderately frequently\",\n             \"4\" = \"Frequently\",\n             \"5\" = \"Very frequently\")\n\ndata_paper[, 2:10] &lt;- lapply(data_paper[, 2:10], function(x) recode[as.character(x)])\ndata_paper[, 13:15] &lt;- lapply(data_paper[, 13:15], function(x) recode2[as.character(x)])\ndata_paper[, 18:20] &lt;- lapply(data_paper[, 18:20], function(x) recode2[as.character(x)])\ndata_paper[, 24] &lt;- lapply(data_paper[, 24], function(x) recode3[as.character(x)])\n\nIn the qualtrics data there are some extra columns that we don’t need, so we’re getting rid of those.\n\ndata_qualtrics &lt;- data_qualtrics %&gt;% dplyr::filter(Finished == \"TRUE\") %&gt;% \n  dplyr::select(-StartDate, -EndDate, -Status, -Progress, -Duration, \n         -RecordedDate, -DistributionChannel, -UserLanguage, -Finished, -Q1, -ResponseId)\n\nThe way people select composer and movement is different for the paper and online surveys, so we need to get them in a matching format.\n\ncomposer_initials &lt;- data.frame(\n  composer = c(\"Beethoven\", \"Hough\"),\n  composer_initial = c(\"B\", \"H\")\n)\n\ndata_long &lt;- data_qualtrics %&gt;%\n  pivot_longer(\n    cols = starts_with(\"Movement\"),\n    names_to = \"source_col\",\n    values_to = \"movement_label\"\n  ) %&gt;%\n  filter(!is.na(movement_label)) %&gt;%\n  mutate(\n    composer = case_when(\n      str_detect(source_col, \"_B_\") ~ \"Beethoven\",\n      str_detect(source_col, \"_H_\") ~ \"Hough\"\n    ),\n    type = case_when(\n      str_detect(source_col, \"_mem$\") ~ \"mem\",\n      str_detect(source_col, \"_story$\") ~ \"story\"\n    ),\n    movement = as.integer(str_extract(movement_label, \"\\\\d+\"))\n  ) %&gt;%\n  left_join(composer_initials, by = \"composer\") %&gt;%\n  mutate(code = paste0(composer_initial, movement))\n\ndata_wide &lt;- data_long %&gt;%\n  dplyr::select(ID, type, code) %&gt;%\n  pivot_wider(\n    names_from = type,\n    values_from = code,\n    names_prefix = \"Movement_\"\n  )\n\nfinal_qualtrics &lt;- data_qualtrics %&gt;%\n  left_join(data_wide, by = \"ID\")\n\nNow we can combine the dataframes:\n\ndata &lt;- bind_rows(data_paper, final_qualtrics)\ndata &lt;- data%&gt;% dplyr::select(-Movement_H_story, -Movement_B_story, -Piece_story, -Movement_H_mem, -Movement_B_mem, -Piece_mem)\n\nNote: to keep track of participants between each half of the survey, they were given a random ID in qualtrics, or were manually numbered in the paper data. We’re keeping hold of these columns for now so we can match the demographic variables to the right participant when we load the post-concert data. But essentially, participants who were online won’t have a participant number, and paper participants won’t have an ID.\nTo view the combined dataset:\n\nlibrary(DT)\ndatatable(data)\n\n\n\n\n\nSECOND HALF\nThese next steps essentially repeat the above, but for the post-concert data.\nLoading the data:\n\ndata_paper2 &lt;- read_csv(\"https://raw.githubusercontent.com/hw3446/Final_Project_PUC/main/input/PUC2.csv\")\n\ndata_qualtrics2 &lt;- read_csv(\"https://raw.githubusercontent.com/hw3446/Final_Project_PUC/main/input_qualtrics/PUC2.csv\")\n\nRecoding / removing unnecessary columns:\n\nrecode &lt;- c(\"1\" = \"Not at all\",\n                \"2\" = \"A small amount of the time\",\n                \"3\" = \"A moderate amount of the time\",\n                \"4\" = \"Most of the time\",\n                \"5\" = \"All of the time\")\n\nrecode2 &lt;- c(\"1\" = \"Not at all\",\n             \"2\" = \"Slightly\",\n             \"3\" = \"Moderately\",\n             \"4\" = \"Mostly\",\n             \"5\" = \"Entirely\")\n\ndata_paper2[, 2:10] &lt;- lapply(data_paper2[, 2:10], function(x) recode[as.character(x)])\ndata_paper2[, 13:15] &lt;- lapply(data_paper2[, 13:15], function(x) recode2[as.character(x)])\ndata_paper2[, 18:20] &lt;- lapply(data_paper2[, 18:20], function(x) recode2[as.character(x)])\n\ndata_qualtrics2 &lt;- data_qualtrics2 %&gt;% dplyr::filter(Finished == \"TRUE\") %&gt;% \n  dplyr::select(-StartDate, -EndDate, -Status, -Progress, -Duration, \n         -RecordedDate, -DistributionChannel, -UserLanguage, -Finished, -ResponseId)\n\nReworking Qualtrics data so the formats match:\n\nfinal_qualtrics2 &lt;- data_qualtrics2 %&gt;%\n    filter(!is.na(Movement_mem)) %&gt;% filter(!is.na(Movement_story)) %&gt;%\n  mutate(Movement_mem = paste0(\"Br\", str_extract(Movement_mem, \"\\\\d+\"))) %&gt;%\n    mutate(Movement_story = paste0(\"Br\", str_extract(Movement_story, \"\\\\d+\")))\n\nCombining Qualtrics and paper data:\n\ndata2 &lt;- bind_rows(data_paper2, final_qualtrics2)\n\nIMPORTANT: We need to pull the demographic information from the first half of the concert and match it to the second half, making sure it’s matched to the right participant. We can do this using the numbers and unique IDs assigned to participants.\n\ndemographics &lt;- data[, c(\"Age\", \"Gender\", \"Music_listening\", \"Practice\", \"Location\", \"Participant_number\", \"ID\")] \n\ndata2 &lt;- data2 %&gt;%\n  mutate(join_key = ifelse(!is.na(Participant_number), Participant_number, ID))\n\ndemographics &lt;- demographics %&gt;%\n  mutate(join_key = ifelse(!is.na(Participant_number), Participant_number, ID))\n\ndata2 &lt;- data2 %&gt;%\n  left_join(demographics, by = \"join_key\")\n\ndata2 &lt;- data2 %&gt;% dplyr::select(-Participant_number.y, -ID.y, -Participant_number.x, -ID.x)\n\nTo view the dataset for the second half, including the matched demographic data:\n\ndatatable(data2)\n\n\n\n\n\nThese are the two dataframes that we’ll be loading and working with in other sections of this blog."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tutorial",
    "section": "",
    "text": "Dataset_overview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of thought types and Movements\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nApr 22, 2025\n\n\nHannah Wilkie\n\n\n\n\n\n\n\n\n\n\n\n\nDid this update??\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nApr 22, 2025\n\n\nHannah Wilkie\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Descriptive 1/Descriptive1.html",
    "href": "posts/Descriptive 1/Descriptive1.html",
    "title": "Distribution of thought types and Movements",
    "section": "",
    "text": "#Part 1 ##Descriptive 1\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(performance)\nlibrary(ordinal)\nlibrary(car)\nlibrary(ggeffects)\nlibrary(gofcat)\nlibrary(brms)\nlibrary(emmeans)\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(MASS) \nlibrary(reshape2) \nlibrary(reshape) \nlibrary(logistf)\nlibrary(corrplot)\n\nFirst we load the data for the first half of the concert, removing columns we don’t want. I’ve also recoded the hall locations into two factors, ‘Downstairs’ and ‘Upstairs’.\n\n#Loading dataset, sheet 1\n\nlibrary(conflicted)\nconflict_prefer(\"filter\", \"dplyr\")\ninput1 &lt;- \"https://raw.githubusercontent.com/hw3446/Final_Project_PUC/main/input/PUC1.csv\"\ndata_paper &lt;- read_csv(input1)\n##\n\nFirst we need to recode some of the values in the dataframe.\n\nrecode &lt;- c(\"1\" = \"Not at all\",\n                \"2\" = \"A small amount of the time\",\n                \"3\" = \"A moderate amount of the time\",\n                \"4\" = \"Most of the time\",\n                \"5\" = \"All of the time\")\n\nrecode2 &lt;- c(\"1\" = \"Not at all\",\n             \"2\" = \"Slightly\",\n             \"3\" = \"Moderately\",\n             \"4\" = \"Mostly\",\n             \"5\" = \"Entirely\")\n\nrecode3 &lt;- c(\"1\" = \"Very rarely\",\n             \"2\" = \"Somewhat rarely\",\n             \"3\" = \"Moderately frequently\",\n             \"4\" = \"Frequently\",\n             \"5\" = \"Very frequently\")\n\ndata_paper[, 2:10] &lt;- lapply(data_paper[, 2:10], function(x) recode[as.character(x)])\ndata_paper[, 13:15] &lt;- lapply(data_paper[, 13:15], function(x) recode2[as.character(x)])\ndata_paper[, 18:20] &lt;- lapply(data_paper[, 18:20], function(x) recode2[as.character(x)])\ndata_paper[, 24] &lt;- lapply(data_paper[, 24], function(x) recode3[as.character(x)])\n\nThen we load the qualtrics data.\n\nlibrary(conflicted)\nconflict_prefer(\"filter\", \"dplyr\")\ninput2 &lt;- \"https://raw.githubusercontent.com/hw3446/Final_Project_PUC/main/input_qualtrics/PUC1.csv\"\ndata_qualtrics &lt;- read_csv(input2)\ndata_qualtrics &lt;- data_qualtrics %&gt;% dplyr::filter(Finished == \"TRUE\") %&gt;% \n  dplyr::select(-StartDate, -EndDate, -Status, -Progress, -Duration, \n         -RecordedDate, -DistributionChannel, -UserLanguage, -Finished, -Q1, -ResponseId)\n\nThe way people select composer and movements is different for the two surveys so we need to get them in a matching format:\n\ncomposer_initials &lt;- data.frame(\n  composer = c(\"Beethoven\", \"Hough\"),\n  composer_initial = c(\"B\", \"H\")\n)\n\ndata_long &lt;- data_qualtrics %&gt;%\n  pivot_longer(\n    cols = starts_with(\"Movement\"),\n    names_to = \"source_col\",\n    values_to = \"movement_label\"\n  ) %&gt;%\n  filter(!is.na(movement_label)) %&gt;%\n  mutate(\n    composer = case_when(\n      str_detect(source_col, \"_B_\") ~ \"Beethoven\",\n      str_detect(source_col, \"_H_\") ~ \"Hough\"\n    ),\n    type = case_when(\n      str_detect(source_col, \"_mem$\") ~ \"mem\",\n      str_detect(source_col, \"_story$\") ~ \"story\"\n    ),\n    movement = as.integer(str_extract(movement_label, \"\\\\d+\"))\n  ) %&gt;%\n  left_join(composer_initials, by = \"composer\") %&gt;%\n  mutate(code = paste0(composer_initial, movement))\n\ndata_wide &lt;- data_long %&gt;%\n  dplyr::select(ID, type, code) %&gt;%\n  pivot_wider(\n    names_from = type,\n    values_from = code,\n    names_prefix = \"Movement_\"\n  )\n\nfinal_qualtrics &lt;- data_qualtrics %&gt;%\n  left_join(data_wide, by = \"ID\")\n\n\n# Combine the data frames\ndata &lt;- bind_rows(data_paper, final_qualtrics)\ndata &lt;- data%&gt;% dplyr::select(-Movement_H_story, -Movement_B_story, -Piece_story, -Movement_H_mem, -Movement_B_mem, -Piece_mem)\n\nA dataframe is created showing thought types in a long format with counts for each frequency.\n\nthought_types &lt;- c(\"Fictional_story\", \"Abstract_shapes\", \"Sensory_sensations\", \"Life_experiences\", \"Media\", \"Music\", \"Future_plans\", \"Building\", \"Everyday\")\n\nthoughts_long &lt;- data %&gt;%\n  pivot_longer(cols = thought_types,\n               names_to = \"Category\", \n               values_to = \"Response\") %&gt;%\n  count(Category, Response) %&gt;% \n  mutate(Response = factor(Response, \n                           levels = c(\"Not at all\", \n                                      \"A small amount of the time\", \n                                      \"A moderate amount of the time\", \n                                      \"Most of the time\", \n                                      \"All of the time\"))) %&gt;% \n  mutate(Category = factor(Category, levels = rev(c(\"Fictional_story\", \n                                                    \"Abstract_shapes\", \n                                                    \"Sensory_sensations\", \n                                                    \"Life_experiences\", \n                                                    \"Media\", \n                                                    \"Music\", \n                                                    \"Future_plans\", \n                                                    \"Building\", \n                                                    \"Everyday\")))) %&gt;% filter(!is.na(Response))\n\nThis dataframe is used for the first plot, which shows the counts for each type of thought during the first half.\n\nggplot(thoughts_long, aes(x = Response, y = Category, fill = n)) +\n  geom_tile(color = \"white\") +  # Add white borders to tiles\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +  # Adjust color gradient\n  labs(title = \"Counts for Thought Types, First Half\", x = NULL, y = NULL, fill = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels\n\n\n\n\n\n\n\n\nThen we examine the counts for the movements people select as invoking the most vivid memory or story.\n\nmems &lt;- data$Movement_mem %&gt;% na.omit() %&gt;% toupper()\nstories &lt;- data$Movement_story %&gt;% na.omit() %&gt;% toupper()\n\n\n# Split values by \";\", \",\", or whitespace\nsplit_values_mem &lt;- unlist(strsplit(mems, \"[; ,]+\"))\nsplit_values_story &lt;- unlist(strsplit(stories, \"[; ,]+\"))\n\n# Trim whitespace\nsplit_values_mem &lt;- trimws(split_values_mem)\nsplit_values_story &lt;- trimws(split_values_story)\n\n# Count occurrences\nvalue_counts_mem &lt;- table(split_values_mem)\nvalue_counts_story &lt;- table(split_values_story)\n\nThe movement counts are then plotted.\n\n#Reorder the Movement factor levels for Beethoven and Hough\n\nrecode_map &lt;- c(\"B1\" = \"Beethoven, Movement 1 — Allegro con brio\",\n                \"B2\" = \"Beethoven, Movement 2 — Adagio affettuoso ed appassionato\",\n                \"B3\" = \"Beethoven, Movement 3 — Scherzo\",\n                \"B4\" = \"Beethoven, Movement 4 — Allegro\",\n                \"H1\" = \"Hough, Movement 1 — Au boulevard\",\n                \"H2\" = \"Hough, Movement 2 — Au parc\",\n                \"H3\" = \"Hough, Movement 3 — À l'hôtel\",\n                \"H4\" = \"Hough, Movement 4 — Au théâtre\",\n                \"H5\" = \"Hough, Movement 5 — À l'église\",\n                \"H6\" = \"Hough, Movement 6 — Au marché\")\n\n\n# Recode values to descriptive names using recode_map\nrecoded_mem &lt;- dplyr::recode(split_values_mem, !!!recode_map)\nrecoded_story &lt;- dplyr::recode(split_values_story, !!!recode_map)\n\n# Convert recoded values to data frames\ndf_mem_counts &lt;- as.data.frame(table(recoded_mem))\ncolnames(df_mem_counts) &lt;- c(\"Movement\", \"count\")\n\ndf_story_counts &lt;- as.data.frame(table(recoded_story))\ncolnames(df_story_counts) &lt;- c(\"Movement\", \"count\")\n\n# Add a Composer column (Beethoven for B1-B4, Hough for H1-H6)\ndf_mem_counts$Composer &lt;- ifelse(grepl(\"^Beethoven\", df_mem_counts$Movement), \"Beethoven\", \"Hough\")\ndf_story_counts$Composer &lt;- ifelse(grepl(\"^Beethoven\", df_story_counts$Movement), \"Beethoven\", \"Hough\")\n\n# Set movement factor levels for proper ordering\ndf_mem_counts$Movement &lt;- factor(df_mem_counts$Movement, levels = recode_map)\ndf_story_counts$Movement &lt;- factor(df_story_counts$Movement, levels = recode_map)\n\n# Plot for 'memories'\nmem_plot &lt;- ggplot(df_mem_counts, aes(x = Movement, y = count, fill = Movement)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~ Composer, scales = \"free_x\") +  # Separate Beethoven & Hough\n  theme_minimal() +\n  labs(title = \"Movement Counts for Memories\", x = \"Movement\", y = \"Count\") +\n theme(axis.title.x = element_blank(),  # Remove x-axis title\n        axis.text.x = element_blank(),   # Remove x-axis labels\n        axis.ticks.x = element_blank()) +\n  scale_fill_brewer(palette = \"Set3\") + \n  guides(fill = guide_legend(title = \"Movement\")) +\n  scale_y_continuous(breaks = scales::breaks_pretty(n = 5))  \n\n# Plot for 'stories'\nstory_plot &lt;- ggplot(df_story_counts, aes(x = Movement, y = count, fill = Movement)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~ Composer, scales = \"free_x\") +  # Separate Beethoven & Hough\n  theme_minimal() +\n  labs(title = \"Movement Counts for Stories\", x = \"Movement\", y = \"Count\") +\n theme(axis.title.x = element_blank(),  # Remove x-axis title\n        axis.text.x = element_blank(),   # Remove x-axis labels\n        axis.ticks.x = element_blank()) +\n  scale_fill_brewer(palette = \"Set3\") + \n  guides(fill = guide_legend(title = \"Movement\")) +\n  scale_y_continuous(breaks = scales::breaks_pretty(n = 5)) \n\nIn the next descriptive phase, we want to look at how demographics variables are associated with different types of thoughts. First, we tidy the demographics data and make sure it’s classed in the right way.\n\n#Creating a 'floor' variable, with 2 factors showing downstairs and upstairs locations.\ndata &lt;- data %&gt;%\n  mutate(Floor = ifelse(Location %in% c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"), \"Downstairs\", \"Upstairs\")) %&gt;% relocate(Floor, .after = Location)\n\n#Removing NA.s?\ndata &lt;- data %&gt;%\n  filter(!is.na(Age) & !is.na(Gender) & !is.na(Music_listening) & !is.na(Floor) & !is.na(Fictional_story) & !is.na(Practice)) %&gt;%\n  filter(!is.infinite(Age) & !is.infinite(Gender) & !is.infinite(Music_listening) & \n         !is.infinite(Floor) & !is.infinite(Fictional_story) & !is.infinite(Practice))\n\n#Making sure demographic variables are classed in the right way.\ndata$Age &lt;- as.numeric(data$Age)\ndata$Practice &lt;- as.numeric(as.character(data$Practice))\ndata$Gender &lt;- factor(data$Gender,  levels = c('Male', 'Female', 'Other'))\ndata$Music_listening &lt;- factor(data$Music_listening, levels = c('Very rarely', 'Somewhat rarely', 'Moderately frequently', 'Frequently', 'Very frequently'))\ndata$Floor &lt;- factor(data$Floor, levels = c('Downstairs', 'Upstairs'))\ndata$Fictional_story &lt;- factor(data$Fictional_story, \n                               levels = c(\"Not at all\", \"A small amount of the time\", \n                                          \"A moderate amount of the time\", \n                                          \"Most of the time\", \"All of the time\"))\n\nVarious descriptive plots can be made, but there are 3 below for age, gender and floor.\n\nDescriptive plot for Age and types of thought – age is converted into a grouped variable:\n\n\n# Create Age bins\ndata &lt;- data %&gt;%\n  mutate(Age_group = cut(Age, \n                         breaks = seq(floor(min(Age, na.rm = TRUE)), \n                                      ceiling(max(Age, na.rm = TRUE)) + 20, by = 5), \n                         include.lowest = TRUE, \n                         right = FALSE))\n\n# List of outcome variables\noutcome_vars &lt;- c(\"Fictional_story\", \"Abstract_shapes\", \"Sensory_sensations\", \n                  \"Life_experiences\", \"Media\", \"Music\", \"Future_plans\", \n                  \"Building\", \"Everyday\")\n\n# Converting outcome variables to factors with consistent levels for each thought type\ndata[outcome_vars] &lt;- lapply(data[outcome_vars], factor, \n                             levels = c(\"Not at all\", \"A small amount of the time\", \n                                        \"A moderate amount of the time\", \"Most of the time\", \n                                        \"All of the time\"))\n\n# Creating a single summary_data dataframe\nsummary_data &lt;- data %&gt;%\n  pivot_longer(cols = all_of(outcome_vars), names_to = \"Outcome\", values_to = \"Response\") %&gt;%\n  group_by(Age_group, Outcome, Response) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Age_group, Outcome) %&gt;%\n  mutate(prop = count / sum(count)) %&gt;%\n  ungroup()\n\n# Looping through each outcome variable to generate plots\nplot_list &lt;- list()\n\nfor (outcome in outcome_vars) {\n    plot_data &lt;- summary_data %&gt;% filter(Outcome == outcome)\n    plot &lt;- ggplot(plot_data, aes(x = Age_group, y = prop, fill = Response)) +\n      geom_bar(stat = \"identity\", position = \"stack\", alpha = 0.8) + \n      labs(x = \"\\nAge Group\", y = \"Proportion\\n\", title = paste(outcome)) +\n      scale_fill_manual(name = \"Response Level\",\n                        values = setNames(c(\"#deebf7\", \"#9ecae1\", \"#3182bd\", \"#08519c\", \"#08306b\"),\n                                          levels(data[[outcome]]))) +\n      theme_minimal() + \n      theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n  plot_list[[outcome]] &lt;- plot\n}\n\n# Arranging plots in a grid and saving\n\ntitle_grob &lt;- textGrob(\"Types of Thoughts by Age Group, First Half\", gp = gpar(fontsize = 16, fontface = \"bold\"))\n\nAge_thoughts_grid &lt;- invisible(grid.arrange(\n  grobs = plot_list, \n  ncol = 3, \n  top = title_grob  \n))\n\n\n\n\n\n\n\n\n\nDescriptive plot for gender and types of thought – for now gender has been filtered for male and female.\n\n\n# Remove missing values + filter\ndata &lt;- data %&gt;%\n  filter(!is.na(Gender)) %&gt;% filter(Gender != 'Other')\n\n# Create a single summary_data dataframe\nsummary_data &lt;- data %&gt;%\n  pivot_longer(cols = all_of(outcome_vars), names_to = \"Outcome\", values_to = \"Response\") %&gt;%\n  group_by(Gender, Outcome, Response) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Gender, Outcome) %&gt;%\n  mutate(prop = count / sum(count)) %&gt;%\n  ungroup()\n\n# Looping through each outcome variable to generate plots\nplot_list &lt;- list()\n\nfor (outcome in outcome_vars) {\n    plot_data &lt;- summary_data %&gt;% filter(Outcome == outcome)\n    plot &lt;- ggplot(plot_data, aes(x = Gender, y = prop, fill = Response)) +\n      geom_bar(stat = \"identity\", position = \"stack\", alpha = 0.8) + \n      labs(x = \"\\nGender\", y = \"Proportion\\n\", title = paste(outcome)) +\n      scale_fill_manual(name = \"Response Level\",\n                        values = setNames(c(\"#deebf7\", \"#9ecae1\", \"#3182bd\", \"#08519c\", \"#08306b\"),\n                                          levels(data[[outcome]]))) +\n      theme_minimal() + \n      theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n  plot_list[[outcome]] &lt;- plot\n}\n\ntitle_grob &lt;- textGrob(\"Types of Thoughts by Gender, First Half\", gp = gpar(fontsize = 16, fontface = \"bold\"))\n\nGender_thoughts_grid &lt;- grid.arrange(\n  grobs = plot_list, \n  ncol = 3, \n  top = title_grob  \n)\n\n\n\n\n\n\n\n\n\nDescriptive plot for floor\n\n\n# Remove missing values\ndata &lt;- data %&gt;%\n  filter(!is.na(Floor))\n\n# Create a single summary_data dataframe\nsummary_data &lt;- data %&gt;%\n  pivot_longer(cols = all_of(outcome_vars), names_to = \"Outcome\", values_to = \"Response\") %&gt;%\n  group_by(Floor, Outcome, Response) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Floor, Outcome) %&gt;%\n  mutate(prop = count / sum(count)) %&gt;%\n  ungroup()\n\n# Looping through each outcome variable to generate plots\nplot_list &lt;- list()\n\nfor (outcome in outcome_vars) {\n    plot_data &lt;- summary_data %&gt;% filter(Outcome == outcome)\n    plot &lt;- ggplot(plot_data, aes(x = Floor, y = prop, fill = Response)) +\n      geom_bar(stat = \"identity\", position = \"stack\", alpha = 0.8) + \n      labs(x = \"\\nFloor\", y = \"Proportion\\n\", title = paste(outcome)) +\n      scale_fill_manual(name = \"Response Level\",\n                        values = setNames(c(\"#deebf7\", \"#9ecae1\", \"#3182bd\", \"#08519c\", \"#08306b\"),\n                                          levels(data[[outcome]]))) +\n      theme_minimal() + \n      theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n  plot_list[[outcome]] &lt;- plot\n}\n\ntitle_grob &lt;- textGrob(\"Types of Thoughts by Floor, First Half\", gp = gpar(fontsize = 16, fontface = \"bold\"))\n\nFloor_thoughts_grid &lt;- grid.arrange(\n  grobs = plot_list, \n  ncol = 3, \n  top = title_grob  \n)\n\n\n\n\n\n\n\n\n\n#Saving the data as a clean file\n#write.csv(data, \"C:/Users/htwil/OneDrive/Documents/Stats 504/Tutorial/data.csv\", row.names = FALSE)"
  }
]